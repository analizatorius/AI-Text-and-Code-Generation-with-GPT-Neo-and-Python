{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import math\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer, Trainer, TrainingArguments, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"D:/_Coding/Python/AI/Text Generators/AI Text and Code Generation with GPT Neo and Python/Transformers/gpt neo 125M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint).cuda()\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIME buffer overflow in email clients, e.g. Solaris mailtool and Outlook.\n",
      "[44, 12789, 11876, 30343, 287, 3053, 7534, 11, 304, 13, 70, 13, 12347, 271, 6920, 25981, 290, 30096, 13]\n"
     ]
    }
   ],
   "source": [
    "descriptions = pd.read_csv(\"descriptions_2.csv\")\n",
    "description_list = list(descriptions[\"Description\"])\n",
    "print(description_list[1])\n",
    "print(tokenizer.encode(description_list[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(tokenizer.encode(description)) for description in description_list])\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_length = sum([len(tokenizer.encode(description)) for description in description_list])\n",
    "average = sum_length/len(description_list)\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "shorter_descriptions = []\n",
    "for description in description_list:\n",
    "    if len(tokenizer.encode(description)) < 100:\n",
    "        shorter_descriptions.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161453\n",
      "187938\n"
     ]
    }
   ],
   "source": [
    "print(len(shorter_descriptions))\n",
    "print(len(description_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.encode(description_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptionDataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "        for txt in txt_list:\n",
    "            encodings_dict = tokenizer(txt, truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DescriptionDataset(shorter_descriptions, tokenizer, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(dataset))\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(torch.utils.data.DataLoader(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(torch.utils.data.DataLoader(dataset[0][0])))\n",
    "print(len(list(torch.utils.data.DataLoader(dataset[0][0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_dataset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_dataset(examples):\n",
    "    concatenated_examples = examples[0][0]\n",
    "    print(len(examples))\n",
    "    print(examples[0][0])\n",
    "    for i in range(1, len(examples)-1):\n",
    "        # if i == 0:\n",
    "        #     continue\n",
    "        # else:\n",
    "        concatenated_examples = torch.cat((concatenated_examples, examples[i][0]), 0)\n",
    "    return concatenated_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatinated_train_dataset = group_dataset(train_dataset)\n",
    "print(concatinated_train_dataset)\n",
    "print(len(concatinated_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(concatinated_train_dataset, 'concatinated_train_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatinated_train_dataset = torch.load('concatinated_train_dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128\n",
    "dataset_length = len(concatinated_train_dataset)\n",
    "print(dataset_length)\n",
    "total_length = (dataset_length // block_size) * block_size\n",
    "print(total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_dataset = torch.split(concatinated_train_dataset, 128)\n",
    "print(split_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(split_train_dataset[-1]))\n",
    "print(len(split_train_dataset[-2]))\n",
    "print(len(split_train_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilgpt2\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}_finetuned_hacks\",\n",
    "    num_train_epochs=10,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\distilgpt2_finetuned_hacks is already a clone of https://huggingface.co/ChronicTronic/distilgpt2_finetuned_hacks. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                                              'labels': torch.stack([f[0] for f in data])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\venv\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 145307\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 3\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 3\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 484360\n",
      "  Number of trainable parameters = 81912576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31b43512dca48038bb7547fd2694c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/484360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to distilgpt2_finetuned_hacks\\checkpoint-500\n",
      "Configuration saved in distilgpt2_finetuned_hacks\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0169, 'learning_rate': 1.9979354199355853e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in distilgpt2_finetuned_hacks\\checkpoint-500\\pytorch_model.bin\n",
      "Saving model checkpoint to distilgpt2_finetuned_hacks\\checkpoint-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8083, 'learning_rate': 1.9958708398711704e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in distilgpt2_finetuned_hacks\\checkpoint-1000\\config.json\n",
      "Model weights saved in distilgpt2_finetuned_hacks\\checkpoint-1000\\pytorch_model.bin\n",
      "Saving model checkpoint to distilgpt2_finetuned_hacks\\checkpoint-1500\n",
      "Configuration saved in distilgpt2_finetuned_hacks\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6984, 'learning_rate': 1.9938062598067556e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in distilgpt2_finetuned_hacks\\checkpoint-1500\\pytorch_model.bin\n",
      "Saving model checkpoint to distilgpt2_finetuned_hacks\\checkpoint-2000\n",
      "Configuration saved in distilgpt2_finetuned_hacks\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.678, 'learning_rate': 1.9917416797423407e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in distilgpt2_finetuned_hacks\\checkpoint-2000\\pytorch_model.bin\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'C:\\\\Users\\\\anali\\\\AppData\\\\Local\\\\Temp\\\\tmpmf8y_pwb\\\\lfs_progress'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\shutil.py:616\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 616\u001b[0m     os\u001b[39m.\u001b[39;49munlink(fullname)\n\u001b[0;32m    617\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\anali\\\\AppData\\\\Local\\\\Temp\\\\tmpmf8y_pwb\\\\lfs_progress'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\tempfile.py:801\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree.<locals>.onerror\u001b[1;34m(func, path, exc_info)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 801\u001b[0m     _os\u001b[39m.\u001b[39;49munlink(path)\n\u001b[0;32m    802\u001b[0m \u001b[39m# PermissionError is raised on FreeBSD for directories\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\anali\\\\AppData\\\\Local\\\\Temp\\\\tmpmf8y_pwb\\\\lfs_progress'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\venv\\lib\\site-packages\\transformers\\trainer.py:1515\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1510\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1512\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1513\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1514\u001b[0m )\n\u001b[1;32m-> 1515\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1516\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1517\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1518\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1519\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1520\u001b[0m )\n",
      "File \u001b[1;32md:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\venv\\lib\\site-packages\\transformers\\trainer.py:1840\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1837\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[0;32m   1838\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m-> 1840\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[0;32m   1841\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1842\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[1;32md:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\venv\\lib\\site-packages\\transformers\\trainer.py:2107\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n\u001b[1;32m-> 2107\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_checkpoint(model, trial, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[0;32m   2108\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_save(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[1;32md:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\venv\\lib\\site-packages\\transformers\\trainer.py:2251\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2248\u001b[0m     torch\u001b[39m.\u001b[39msave(rng_states, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrng_state_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mprocess_index\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   2250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[1;32m-> 2251\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_push_from_checkpoint(output_dir)\n\u001b[0;32m   2253\u001b[0m \u001b[39m# Maybe delete some older checkpoints.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[1;32md:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\venv\\lib\\site-packages\\transformers\\trainer.py:3418\u001b[0m, in \u001b[0;36mTrainer._push_from_checkpoint\u001b[1;34m(self, checkpoint_folder)\u001b[0m\n\u001b[0;32m   3416\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3417\u001b[0m         commit_message \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining in progress, epoch \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 3418\u001b[0m     _, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepo\u001b[39m.\u001b[39;49mpush_to_hub(\n\u001b[0;32m   3419\u001b[0m         commit_message\u001b[39m=\u001b[39;49mcommit_message, blocking\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, auto_lfs_prune\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   3420\u001b[0m     )\n\u001b[0;32m   3421\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   3422\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_strategy \u001b[39m==\u001b[39m HubStrategy\u001b[39m.\u001b[39mCHECKPOINT:\n\u001b[0;32m   3423\u001b[0m         \u001b[39m# Move back the checkpoint to its place\u001b[39;00m\n",
      "File \u001b[1;32md:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\venv\\lib\\site-packages\\huggingface_hub\\repository.py:1438\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[1;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_add(auto_lfs_track\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_commit(commit_message)\n\u001b[1;32m-> 1438\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgit_push(\n\u001b[0;32m   1439\u001b[0m     upstream\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39morigin \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_branch\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1440\u001b[0m     blocking\u001b[39m=\u001b[39;49mblocking,\n\u001b[0;32m   1441\u001b[0m     auto_lfs_prune\u001b[39m=\u001b[39;49mauto_lfs_prune,\n\u001b[0;32m   1442\u001b[0m )\n",
      "File \u001b[1;32md:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\venv\\lib\\site-packages\\huggingface_hub\\repository.py:1213\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[1;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                 logger\u001b[39m.\u001b[39mwarning(stderr)\n\u001b[0;32m   1212\u001b[0m             \u001b[39mif\u001b[39;00m return_code:\n\u001b[1;32m-> 1213\u001b[0m                 \u001b[39mraise\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError(\n\u001b[0;32m   1214\u001b[0m                     return_code, process\u001b[39m.\u001b[39margs, output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr\n\u001b[0;32m   1215\u001b[0m                 )\n\u001b[0;32m   1217\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m   1218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(exc\u001b[39m.\u001b[39mstderr)\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\contextlib.py:124\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    125\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\_Coding\\Python\\AI\\Text Generators\\AI Text and Code Generation with GPT Neo and Python\\venv\\lib\\site-packages\\huggingface_hub\\repository.py:410\u001b[0m, in \u001b[0;36m_lfs_log_progress\u001b[1;34m()\u001b[0m\n\u001b[0;32m    407\u001b[0m exit_event\u001b[39m.\u001b[39mset()\n\u001b[0;32m    408\u001b[0m x\u001b[39m.\u001b[39mjoin()\n\u001b[1;32m--> 410\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mGIT_LFS_PROGRESS\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m current_lfs_progress_value\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\tempfile.py:826\u001b[0m, in \u001b[0;36mTemporaryDirectory.__exit__\u001b[1;34m(self, exc, value, tb)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc, value, tb):\n\u001b[1;32m--> 826\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcleanup()\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\tempfile.py:830\u001b[0m, in \u001b[0;36mTemporaryDirectory.cleanup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcleanup\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    829\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalizer\u001b[39m.\u001b[39mdetach():\n\u001b[1;32m--> 830\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rmtree(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\tempfile.py:812\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    809\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 812\u001b[0m _shutil\u001b[39m.\u001b[39;49mrmtree(name, onerror\u001b[39m=\u001b[39;49monerror)\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\shutil.py:740\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[39m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m \u001b[39mreturn\u001b[39;00m _rmtree_unsafe(path, onerror)\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\shutil.py:618\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    616\u001b[0m             os\u001b[39m.\u001b[39munlink(fullname)\n\u001b[0;32m    617\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m--> 618\u001b[0m             onerror(os\u001b[39m.\u001b[39;49munlink, fullname, sys\u001b[39m.\u001b[39;49mexc_info())\n\u001b[0;32m    619\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    620\u001b[0m     os\u001b[39m.\u001b[39mrmdir(path)\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\tempfile.py:804\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree.<locals>.onerror\u001b[1;34m(func, path, exc_info)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[39m# PermissionError is raised on FreeBSD for directories\u001b[39;00m\n\u001b[0;32m    803\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mIsADirectoryError\u001b[39;00m, \u001b[39mPermissionError\u001b[39;00m):\n\u001b[1;32m--> 804\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_rmtree(path)\n\u001b[0;32m    805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    806\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\tempfile.py:812\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    809\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 812\u001b[0m _shutil\u001b[39m.\u001b[39;49mrmtree(name, onerror\u001b[39m=\u001b[39;49monerror)\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\shutil.py:740\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[39m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m \u001b[39mreturn\u001b[39;00m _rmtree_unsafe(path, onerror)\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\shutil.py:599\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    597\u001b[0m         entries \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(scandir_it)\n\u001b[0;32m    598\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m--> 599\u001b[0m     onerror(os\u001b[39m.\u001b[39;49mscandir, path, sys\u001b[39m.\u001b[39;49mexc_info())\n\u001b[0;32m    600\u001b[0m     entries \u001b[39m=\u001b[39m []\n\u001b[0;32m    601\u001b[0m \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m entries:\n",
      "File \u001b[1;32mD:\\Programs\\Python394\\lib\\shutil.py:596\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rmtree_unsafe\u001b[39m(path, onerror):\n\u001b[0;32m    595\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         \u001b[39mwith\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(path) \u001b[39mas\u001b[39;00m scandir_it:\n\u001b[0;32m    597\u001b[0m             entries \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(scandir_it)\n\u001b[0;32m    598\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'C:\\\\Users\\\\anali\\\\AppData\\\\Local\\\\Temp\\\\tmpmf8y_pwb\\\\lfs_progress'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f76e36657fbddc5945ff4de74486ef0d72b3bafbe1d46d3f3b37ccedafbcd958"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
